# -*- coding: utf-8 -*-
"""D23CSA001.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xp_j3mFE3bcNEFbYfVELVrCsPnPgNzk8

### Importing the libraries
"""

import os
import torch
import torchvision
import torch.nn as nn
import numpy as np
import torchvision.models as models
import matplotlib.pyplot as plt
from torchvision.datasets import ImageFolder
from torchvision.datasets.folder import default_loader
from torchvision.transforms import functional as F
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
from torchvision.utils import make_grid
import torch.nn.init as init

train_data_path = "/home/maverick/MTech_sem2/Deep_learning/DL_assign_3/"
train_mask_path = "/home/maverick/MTech_sem2/Deep_learning/DL_assign_3/"
test_data_path = "/home/maverick/MTech_sem2/Deep_learning/DL_assign_3/"
test_mask_path = "/home/maverick/MTech_sem2/Deep_learning/DL_assign_3/"

"""### Transformation to be applied on the dataset"""

image_transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    # transforms.RandomRotation(degrees=15),
    # transforms.RandomVerticalFlip(),
    # transforms.RandomHorizontalFlip(),
    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])


])

mask_transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    # transforms.RandomRotation(degrees=15),
    # transforms.RandomVerticalFlip(),
    # transforms.RandomHorizontalFlip(),



])

"""### Making custom dataset"""

class CustomDataset(Dataset):
    def __init__(self, data_path, mask_path, mode='train',image_transform=image_transform,mask_transform=mask_transform):
        self.data_path = data_path
        self.mask_path = mask_path
        self.image_transform = image_transform
        self.mask_transform = mask_transform
        self.mode = mode
        if self.mode == 'train':
            self.image_folder = "train"
            self.mask_folder = "train_masks"
        elif self.mode == 'test':
            self.image_folder = "test"
            self.mask_folder = "test_masks"


        self.image_files = [f for f in os.listdir(os.path.join(self.data_path, self.image_folder)) if f.endswith('.jpg')]
        self.mask_files = [f for f in os.listdir(os.path.join(self.mask_path, self.mask_folder)) if f.endswith('.png')]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = os.path.join(self.data_path, self.image_folder, self.image_files[idx])
        mask_name = os.path.join(self.mask_path, self.mask_folder, self.mask_files[idx])

        image = Image.open(img_name).convert("RGB")
        mask = Image.open(mask_name)



        if self.image_transform:
            image = self.image_transform(image)

            mask = self.mask_transform(mask)

        return image, mask

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

train_dataset = CustomDataset(data_path=train_data_path, mask_path=train_mask_path, mode='train', image_transform=image_transform,mask_transform=mask_transform)
test_dataset = CustomDataset(data_path=test_data_path, mask_path=test_mask_path, mode='test', image_transform=image_transform,mask_transform=mask_transform)

train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=2)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=2)

images, masks = next(iter(train_dataloader))

print(images.shape)
print(masks.shape)

def imshow(images):
    img_np = images.numpy()
    plt.imshow(np.transpose(img_np,(1,2,0)))
    plt.axis('off')
    plt.show()

"""### Visualizing the samples with Masks"""

imshow(make_grid(images))

imshow(make_grid(masks))



"""### Pretrain model"""

Mobilenet_encoder = models.mobilenet_v2(pretrained=True)

Mobilenet_encoder = nn.Sequential(*list(Mobilenet_encoder.children())[:-1])

for param in Mobilenet_encoder.parameters():
    param.requires_grad = False

Mobilenet_encoder.to(device)

"""### defining the custom decoder"""

class Custom_Decoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(Custom_Decoder, self).__init__()

        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)
        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)

        self.upconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, output_padding=1)
        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1)
        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1)
        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1)
        self.upconv5 = nn.ConvTranspose2d(64, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)

        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

        for m in self.modules():
            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):
                init.xavier_uniform_(m.weight)

    def forward(self, x):
        x1 = self.relu(self.conv1(x))
        x2 = self.relu(self.conv2(x1))
        x3 = self.relu(self.conv3(x2))
        x4 = self.relu(self.conv4(x3))
        x5 = self.relu(self.conv5(x4))

        x = self.relu(self.upconv1(x5))
        x = self.relu(self.upconv2(x))
        x = self.relu(self.upconv3(x))
        x = self.relu(self.upconv4(x))
        x = self.sigmoid(self.upconv5(x))

        return x

decoder = Custom_Decoder(1280,1)
decoder.to(device)

find_loss= nn.BCELoss()


optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01,betas=(0.9,0.99))

def calculate_iou(outputs, targets):
    epsilon = 1e-6
    intersection = (outputs*targets).sum()
    union = outputs.sum() + targets.sum() - intersection
    iou = (intersection + epsilon) / (union + epsilon)
    return iou

def calculate_dice_score(outputs, targets):
    epsilon = 1e-6
    intersection = (outputs*targets).sum()
    union = outputs.sum() + targets.sum()
    dice_score = (2.0 * intersection + epsilon) / (union + epsilon)
    return dice_score

def plot_loss(train_loss, val_loss):
    epochs = range(1, len(train_loss) + 1)
    plt.plot(epochs, train_loss, label='Training Loss')
    plt.plot(epochs, val_loss, label='Validation/Testing Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation/Testing Loss')
    plt.legend()
    plt.show()

def visualize_samples(images, predictions, masks):
    num_samples = len(images)
    for i in range(num_samples):
        plt.figure(figsize=(12, 4))

        image_np = images[i].cpu().permute(1, 2, 0)
        prediction_np = predictions[i].squeeze().cpu()
        mask_np = masks[i].squeeze().cpu()

        # Use when no gpu

        # image_np = images[i].permute(1, 2, 0)
        # prediction_np = predictions[i].squeeze()
        # mask_np = masks[i].squeeze()

        plt.subplot(1, 3, 1)
        plt.imshow(image_np)
        plt.title('Original Image')
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.imshow(prediction_np, cmap='gray')
        plt.title('Generated Mask')
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.imshow(mask_np, cmap='gray')
        plt.title('Ground Truth Mask')
        plt.axis('off')

        plt.show()

"""### Training loop"""

train_loss_history = []
test_loss_history= []
i = 1
for epoch in range(30):
    epoch_train_loss = 0.0
    decoder.train()

    for images, masks in train_dataloader:
        images, masks = images.to(device), masks.to(device)
        optimizer.zero_grad()

        encoder_output = Mobilenet_encoder(images)
        decoder_output = decoder(encoder_output)
        # print(decoder_output)
        loss = find_loss(decoder_output, masks)

        loss.backward()
        optimizer.step()

        epoch_train_loss += loss.item() * images.size(0)
        # epoch_train_loss += loss.item()


    epoch_train_loss /= len(train_dataloader.dataset)
    train_loss_history.append(epoch_train_loss)


    decoder.eval()

    with torch.no_grad():
        epoch_test_loss = 0.0
        epoch_iou = 0.0
        epoch_dice_score = 0.0
        num_batches = 0

        for test_img, test_masks in test_dataloader:
            test_img, test_masks = test_img.to(device), test_masks.to(device)

            test_encoder_output = Mobilenet_encoder(test_img)
            test_decoder_output = decoder(test_encoder_output)
            #print(test_decoder_output)


            test_loss = find_loss(test_decoder_output, test_masks)
            epoch_test_loss += test_loss.item() * test_img.size(0)


            predictions = ((test_decoder_output)>0.5).float()
            # print(predictions)


            epoch_iou += calculate_iou(predictions, test_masks)
            epoch_dice_score += calculate_dice_score(predictions, test_masks)

            num_batches += 1

            if i== 1 and epoch==29:
                i+=1
                visualize_samples(test_img, predictions, test_masks)

    epoch_test_loss /= len(test_dataloader.dataset)
    test_loss_history.append(epoch_test_loss)
    epoch_iou /= num_batches
    epoch_dice_score /= num_batches


    print(f"Epoch: {epoch + 1}, Training Loss: {epoch_train_loss}, Testing Loss: {epoch_test_loss}, IoU: {epoch_iou}, Dice Score: {epoch_dice_score}")

"""### Train Test loss plot"""

plot_loss(train_loss_history, test_loss_history)

"""### Task 2 - Fine tuning"""

Mobilenet_encoder_FT = models.mobilenet_v2(pretrained=True)

Mobilenet_encoder_FT = nn.Sequential(*list(Mobilenet_encoder_FT.children())[:-1])

Mobilenet_encoder_FT.to(device)



decoder_FT = Custom_Decoder(1280,1)
decoder_FT.to(device)

find_loss= nn.BCELoss()


optimizer = torch.optim.Adam([
    {'params': Mobilenet_encoder_FT.parameters(), 'lr': 1e-4},
    {'params': decoder_FT.parameters(), 'lr': 1e-3}
])

"""### Training loop for Fine tuning"""

train_loss_history_FT = []
test_loss_history_FT = []
i = 1
for epoch in range(30):
    epoch_train_loss = 0.0
    Mobilenet_encoder_FT.train()
    decoder_FT.train()

    for images, masks in train_dataloader:
        images, masks = images.to(device), masks.to(device)
        optimizer.zero_grad()

        encoder_output = Mobilenet_encoder_FT(images)
        decoder_output = decoder_FT(encoder_output)
        # print(decoder_output)
        loss = find_loss(decoder_output, masks)

        loss.backward()
        optimizer.step()

        epoch_train_loss += loss.item() * images.size(0)
        # epoch_train_loss += loss.item()


    epoch_train_loss /= len(train_dataloader.dataset)
    train_loss_history_FT.append(epoch_train_loss)

    Mobilenet_encoder_FT.eval()
    decoder_FT.eval()

    with torch.no_grad():
        epoch_test_loss = 0.0
        epoch_iou = 0.0
        epoch_dice_score = 0.0
        num_batches = 0

        for test_img, test_masks in test_dataloader:
            test_img, test_masks = test_img.to(device), test_masks.to(device)

            test_encoder_output = Mobilenet_encoder_FT(test_img)
            test_decoder_output = decoder_FT(test_encoder_output)
            #print(test_decoder_output)


            test_loss = find_loss(test_decoder_output, test_masks)
            epoch_test_loss += test_loss.item() * test_img.size(0)


            predictions = ((test_decoder_output)>0.5).float()
            # print(predictions)


            epoch_iou += calculate_iou(predictions, test_masks)
            epoch_dice_score += calculate_dice_score(predictions, test_masks)

            num_batches += 1

            if i== 1 and epoch==29:
                i+=1
                visualize_samples(test_img, predictions, test_masks)

    epoch_test_loss /= len(test_dataloader.dataset)
    test_loss_history_FT.append(epoch_test_loss)
    epoch_iou /= num_batches
    epoch_dice_score /= num_batches


    print(f"Epoch: {epoch + 1}, Training Loss: {epoch_train_loss}, Testing Loss: {epoch_test_loss}, IoU: {epoch_iou}, Dice Score: {epoch_dice_score}")

"""### Train Test loss plot - fine tuning"""

plot_loss(train_loss_history_FT, test_loss_history_FT)

