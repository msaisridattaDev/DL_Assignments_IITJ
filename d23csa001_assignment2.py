# -*- coding: utf-8 -*-
"""D23CSA001.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13va2kBnJczEYW4BeRhBFHOZwovguiIpi

This code is useful in data loading, visualization and exploration. You are free to modify the code. The code has dependecy on Pytorch Lightning data module. However, you may use Pytorch as well.

**Introduction to Dataset**

The data has a total of 10 classes with 40 samples each. Make sure while working with the data, **esc10=True**. In the assignment, you are required to perform 4-fold validation. This dataset has been already divided into 5-folds. The column 'fold' in the metafile denotes the sample in a particular fold. Moreover, first folds is considered for test, rest for 4-fold validation.
"""

# DL Assignment 2
# Authors: Kopal Rastogi, Ishan Mishra
# Keywords: None
# Assumptions: None

# Installing the requirements
print('Installing Requirements... ',end='')
!pip install lightning
print('Done')

import pdb

# Importing Libraries
print('Importing Libraries... ',end='')
import os
from pathlib import Path
import pandas as pd
import torchaudio
import zipfile
from torchaudio.transforms import Resample
import IPython.display as ipd
from matplotlib import pyplot as plt
from tqdm import tqdm
import pytorch_lightning as pl
from torch.utils.data import Dataset, DataLoader
import torch
import torch.nn as nn
import math
import torch.optim as optim
import seaborn as sns
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,f1_score
import wandb
print('Done')

# #Use for colab
# # Download data
# # Your code here
# print('Downlading data... ', end='')
# from google.colab import drive
# drive.mount('/content/drive')

# print('Done')

# #Use for colab
# # Extract data
# with zipfile.ZipFile("/content/drive/MyDrive/Archive.zip", 'r') as zip_ref:
#     zip_ref.extractall("/content/")

# #If using drive
# path = Path('/content/meta/esc50.csv')
# df = pd.read_csv(path)

#If using local machine
path = Path('/home/maverick/MTech_sem2/Deep_learning/DL_assign_2/Archive/meta/esc50.csv')
df = pd.read_csv(path)

df.head()

df['target']

# #If using google colab
# # Getting list of raw audio files
# path = Path('/content/audio')
# wavs = list(path.glob('*'))  # List all audio files in the 'audio' directory using pathlib.Path.glob
# print(len(wavs))

#If using local machine
from pathlib import Path

path = Path('/home/maverick/MTech_sem2/Deep_learning/DL_assign_2/Archive/audio/')
audio_extensions = ['.wav']  # Add other audio file extensions as needed

wavs = [file for file in path.glob('*') if file.suffix.lower() in audio_extensions]
print(len(wavs))

# Visualizing data
waveform, sample_rate = torchaudio.load(wavs[1])  # Load the waveform and sample rate of the first audio file using torchaudio

print("Shape of waveform: {}".format(waveform.size()))  # Print the shape of the waveform tensor
print("Sample rate of waveform: {}".format(sample_rate))  # Print the sample rate of the audio file

# Plot the waveform using matplotlib
plt.figure()
plt.plot(waveform.t().numpy())  # Transpose and convert the waveform tensor to a NumPy array for plotting

# Display the audio using IPython.display.Audio
ipd.Audio(waveform, rate=sample_rate)  # Create an interactive audio player for the loaded waveform

class CustomDataset(Dataset):
    def __init__(self, dataset, **kwargs):
        # Initialize CustomDataset object with relevant parameters
        # dataset: "train", "val", or "test"
        # kwargs: Additional parameters like data directory, dataframe, folds, etc.

        # Extract parameters from kwargs
        self.data_directory = kwargs["data_directory"]
        self.data_frame = kwargs["data_frame"]
        self.validation_fold = kwargs["validation_fold"]
        self.testing_fold = kwargs["testing_fold"]
        self.esc_10_flag = kwargs["esc_10_flag"]
        self.file_column = kwargs["file_column"]
        self.label_column = kwargs["label_column"]
        self.sampling_rate = kwargs["sampling_rate"]
        self.new_sampling_rate = kwargs["new_sampling_rate"]
        self.sample_length_seconds = kwargs["sample_length_seconds"]

        # Filter dataframe based on esc_10_flag and data_type
        if self.esc_10_flag:
            self.data_frame = self.data_frame.loc[self.data_frame['esc10'] == True]

        if dataset == "train":
            self.data_frame = self.data_frame.loc[
                (self.data_frame['fold'] != self.validation_fold) & (self.data_frame['fold'] != self.testing_fold)]
        elif dataset == "val":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.validation_fold]
        elif dataset == "test":
            self.data_frame = self.data_frame.loc[self.data_frame['fold'] == self.testing_fold]

        # Get unique categories from the filtered dataframe
        self.categories = sorted(self.data_frame[self.label_column].unique())


        # Initialize lists to hold file names, labels, and folder numbers
        self.file_names = []
        self.labels = []

        # Initialize dictionaries for category-to-index and index-to-category mapping
        self.category_to_index = {}
        self.index_to_category = {}

        for i, category in enumerate(self.categories):
            self.category_to_index[category] = i
            self.index_to_category[i] = category

        # Populate file names and labels lists by iterating through the dataframe
        for ind in tqdm(range(len(self.data_frame))):
            row = self.data_frame.iloc[ind]
            file_path = self.data_directory/ row[self.file_column]
            self.file_names.append(file_path)
            self.labels.append(self.category_to_index[row[self.label_column]])

        self.resampler = torchaudio.transforms.Resample(self.sampling_rate, self.new_sampling_rate)

        # Window size for rolling window sample splits (unfold method)
        if self.sample_length_seconds == 2:
            self.window_size = self.new_sampling_rate * 2
            self.step_size = int(self.new_sampling_rate * 0.75)
        else:
            self.window_size = self.new_sampling_rate
            self.step_size = int(self.new_sampling_rate * 0.5)

    def __getitem__(self, index):
        # Split audio files with overlap, pass as stacked tensors tensor with a single label
        path = self.file_names[index]
        audio_file = torchaudio.load(path, format=None, normalize=True)
        audio_tensor = self.resampler(audio_file[0])
        splits = audio_tensor.unfold(1, self.window_size, self.step_size)
        samples = splits.permute(1, 0, 2)

        labels = torch.tensor([self.labels[index]] * samples.size(0), dtype=torch.long)


        return samples,labels
        # return audio_tensor,self.labels
        # samples_list = [split.unsqueeze(0) for split in splits]  # List of individual windows
        # labels_list = [self.labels[index] for _ in range(len(samples_list))]  # List of corresponding labels

        # return samples_list, labels_list

    def __len__(self):
        return len(self.file_names)

class CustomDataModule(pl.LightningDataModule):
    def __init__(self, **kwargs):
        # Initialize the CustomDataModule with batch size, number of workers, and other parameters
        super().__init__()
        self.batch_size = kwargs["batch_size"]
        self.num_workers = kwargs["num_workers"]
        self.data_module_kwargs = kwargs

    def setup(self, stage=None):
        # Define datasets for training, validation, and testing during Lightning setup

        # If in 'fit' or None stage, create training and validation datasets
        if stage == 'fit' or stage is None:
            self.training_dataset = CustomDataset(dataset="train", **self.data_module_kwargs)
            self.validation_dataset = CustomDataset(dataset="val", **self.data_module_kwargs)

        # If in 'test' or None stage, create testing dataset
        if stage == 'test' or stage is None:
            self.testing_dataset = CustomDataset(dataset="test", **self.data_module_kwargs)

    def train_dataloader(self):
        # Return DataLoader for training dataset
        return DataLoader(self.training_dataset,
                          batch_size=self.batch_size,
                          shuffle=True,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def val_dataloader(self):
        # Return DataLoader for validation dataset
        return DataLoader(self.validation_dataset,
                          batch_size=self.batch_size,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def test_dataloader(self):
        # Return DataLoader for testing dataset
        return DataLoader(self.testing_dataset,
                          batch_size=32,
                          shuffle=False,
                          collate_fn=self.collate_function,
                          num_workers=self.num_workers)

    def collate_function(self, data):
        """
        Collate function to process a batch of examples and labels.

        Args:
            data: a tuple of 2 tuples with (example, label) where
                example are the split 1 second sub-frame audio tensors per file
                label = the label

        Returns:
            A list containing examples (concatenated tensors) and labels (flattened tensor).
        """
        examples, labels = zip(*data)
        examples = torch.cat(examples)
        #examples = torch.stack(examples)
        labels = torch.cat(labels)


        return [examples, labels]

# Data Setup
test_samp = 1 #""" Do not change this!! """
valid_samp = 4 # Use any value ranging from 2 to 5 for k-fold validation (valid_fold)
batch_size = 8 # Free to change
num_workers = 2 # Free to change
custom_data_module = CustomDataModule(batch_size=batch_size,
                                      num_workers=num_workers,
                                      data_directory=path,
                                      data_frame=df,
                                      validation_fold=valid_samp,
                                      testing_fold=test_samp,  # set to 0 for no test set
                                      esc_10_flag=True,
                                      file_column='filename',
                                      label_column='category',
                                      sampling_rate=44100,
                                      new_sampling_rate=16000,  # new sample rate for input
                                      sample_length_seconds=1  # new length of input in seconds
                                      )

custom_data_module.setup()

# Data Exploration
print('Class Label: ',custom_data_module.training_dataset[0][1])  # this prints the class label
print('Shape of data sample tensor: ', custom_data_module.training_dataset[0][0].shape)  # this prints the shape of the sample (Frames, Channel, Features)

dataiter = iter(custom_data_module.training_dataset)
images, labels = next(dataiter)  # Use the next() function to get the next batch
print(type(images))
print(images.shape)

print('Shape of data sample tensor: ', custom_data_module.training_dataset[0][0].shape)

# Dataloader(s)
x = next(iter(custom_data_module.train_dataloader()))
y = next(iter(custom_data_module.val_dataloader()))
z = next(iter(custom_data_module.test_dataloader()))
print('Train Dataloader:')
print(x)
print('Validation Dataloader:')
print(y)
print('Test Dataloader:')
print(z)

x[0].shape,x[1].shape

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(device)

train_data = custom_data_module.train_dataloader()
val_data   = custom_data_module.val_dataloader()
test_data  = custom_data_module.test_dataloader()

"""# CNN architecture"""

class CNN(nn.Module):
  def __init__(self):
    super(CNN,self).__init__()

    self.convolution1 = nn.Sequential(
        nn.Conv1d(in_channels=1,out_channels=16,kernel_size=3,stride=1,padding=3),
        nn.ReLU(),
        nn.MaxPool1d(kernel_size=2,stride=2)
    )

    self.convolution2 = nn.Sequential(
        nn.Conv1d(in_channels=16,out_channels=8,kernel_size=3,stride=1,padding=2),
        nn.ReLU(),
        nn.MaxPool1d(kernel_size=2,stride=2)
    )

    self.convolution3 = nn.Sequential(
        nn.Conv1d(in_channels=8,out_channels=4,kernel_size=3,stride=2,padding=1),
        nn.ReLU(),
        nn.MaxPool1d(kernel_size=2,stride=2)
    )

    self.fully_connected_layer1 = nn.Linear(1000*4,32)
    self.fully_connected_layer2 = nn.Linear(32,10)

  def forward(self,x):
    relu = nn.ReLU()
    softmax = nn.Softmax()
    x = self.convolution1(x)

    x = self.convolution2(x)

    x = self.convolution3(x)


    x = nn.Flatten()(x)

    x = self.fully_connected_layer1(x)
    x = relu(x)
    output = self.fully_connected_layer2(x)

    #x = softmax(x)

    return output

torch.cuda.empty_cache()

torch.manual_seed(42)

cnn = CNN()

cnn.to(device)

# For train_validation
optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001,betas=(0.9,0.99))

# optimizer =  torch.optim.SGD(cnn.parameters(),lr=0.01,momentum=0.9,nesterov=True)
find_loss = nn.CrossEntropyLoss()
loss = []
train_loss = 0.0
validation_loss = []
validation_accuracy = []
test_loss_lst= []
test_accuracy_lst = []

train_accuracy = 0.0

# # for colab
# !pip install wandb



"""# CNN train validation"""

wandb.login()



run = wandb.init(project="Deep_learning_assignment2", name="Audio classification using CNN -> Train -validation")

for epoch in range(100):
    cnn.train()
    train_batch_loss = 0.0
    correct_predictions_train = 0.0
    total_samples_train = 0

    for i, (input_data, labels) in enumerate(train_data):
        input_data = input_data.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        output = cnn(input_data)
        current_loss = find_loss(output, labels)

        train_batch_loss += current_loss.item()
        predictions = torch.max(output.data, 1)[1]
        correct_predictions_train += (predictions==labels).sum().item()
        total_samples_train += labels.size(0)

        current_loss.backward()
        optimizer.step()


        average_loss_train = train_batch_loss / len(train_data)
        accuracy_train = (correct_predictions_train / total_samples_train)*100


        cnn.eval()
        val_batch_loss = 0.0
        correct_predictions_val = 0.0
        total_samples_val = 0

        with torch.no_grad():
            for input_data, labels in val_data:
                input_data = input_data.to(device)
                labels = labels.to(device)

                output = cnn(input_data)
                current_loss_val = find_loss(output, labels)

                val_batch_loss += current_loss_val.item()
                predictions_val = torch.max(output.data, 1)[1]
                correct_predictions_val += (predictions_val==labels).sum().item()
                total_samples_val += labels.size(0)


        average_loss_val = val_batch_loss / len(val_data)
        accuracy_val = (correct_predictions_val / total_samples_val)*100


    wandb.log({

            "epoch": epoch + 1,
            "train_loss": average_loss_train,
            "train_accuracy": accuracy_train,
            "val_loss": average_loss_val,
            "val_accuracy": accuracy_val
        })

    if (i + 1) % 15 == 0:
             accuracy = correct_predictions_train / total_samples_train
             print("Train epoch {} loss: {} Accuracy_train: {} Accuracy_val: {}".format(epoch + 1, current_loss,accuracy_train,accuracy_val))


run.finish()

# torch.save(cnn.state_dict(), "best_model_cnn_audio_2.pt")

"""# CNN Train - test"""

test_predictions = []
test_labels = []

torch.manual_seed(42)

cnn_test = CNN()
cnn_test.to(device)

# For train_validation
optimizer = torch.optim.Adam(cnn_test.parameters(), lr=0.001,betas=(0.9,0.99))

run = wandb.init(project="Deep_learning_assignment2", name="Audio classification using CNN -> Train -test")

for epoch in range(100):
    cnn_test.train()
    train_batch_loss = 0.0
    correct_predictions_train = 0.0
    total_samples_train = 0

    for i, (input_data, labels) in enumerate(train_data):
        input_data = input_data.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        output = cnn_test(input_data)
        current_loss = find_loss(output, labels)

        train_batch_loss += current_loss.item()
        predictions = torch.max(output.data, 1)[1]
        correct_predictions_train += (predictions==labels).sum().item()
        total_samples_train += labels.size(0)

        current_loss.backward()
        optimizer.step()


        average_loss_train = train_batch_loss / len(train_data)
        accuracy_train = (correct_predictions_train / total_samples_train)*100

        cnn_test.eval()
        test_batch_loss = 0.0
        correct_predictions_test = 0.0
        total_samples_test = 0
        with torch.no_grad():
            for input_data, labels in test_data:
                input_data = input_data.to(device)
                labels = labels.to(device)

                output = cnn_test(input_data)
                current_loss_test = find_loss(output,labels)

                test_batch_loss += current_loss_test.item()
                _, predictions_test = torch.max(output.data, 1)

                correct_predictions_test += (predictions_test == labels).sum().item()
                total_samples_test += labels.size(0)


        average_loss_test = test_batch_loss / len(test_data)
        accuracy_test = (correct_predictions_test/total_samples_test)*100


    wandb.log({

            "epoch": epoch + 1,
            "train_loss": average_loss_train,
            "train_accuracy": accuracy_train,
            "test_loss": average_loss_test,
            "test_accuracy": accuracy_test
        })

    if (i + 1) % 15 == 0:
             accuracy = correct_predictions_train / total_samples_train
             print("Train epoch {} loss: {} Accuracy_train: {} Accuracy_test: {}".format(epoch + 1, current_loss,accuracy_train,accuracy_test))


run.finish()

from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import label_binarize

test_predictions = []
test_labels = []

with torch.no_grad():
    for input_data, labels in test_data:
        input_data = input_data.to(device)
        labels = labels.to(device)

        output = cnn_test(input_data)
        _, predictions_test = torch.max(output.data, 1)

        test_predictions.extend(predictions_test.cpu().numpy())
        test_labels.extend(labels.cpu().numpy())


accuracy_test = accuracy_score(test_labels, test_predictions)*100

accuracy = accuracy_score(test_labels, test_predictions)
confusion = confusion_matrix(test_labels, test_predictions)
f1_scores = f1_score(test_labels, test_predictions, average=None)
classification_rep = classification_report(test_labels, test_predictions)

class_auc_roc = {}

with torch.no_grad():
    for class_label in set(test_labels):

        binary_test_labels = [1 if label == class_label else 0 for label in test_labels]
        binary_test_predictions = [1 if pred == class_label else 0 for pred in test_predictions]


        auc_roc_class = roc_auc_score(binary_test_labels, binary_test_predictions)


        class_auc_roc[class_label] = auc_roc_class

print("AUC-ROC scores for each class:", class_auc_roc)

class_labels = sorted(list(set(test_labels + test_predictions)))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues_r', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Visualize F1 scores
plt.figure(figsize=(10, 6))
plt.bar(class_labels, f1_scores,color = 'cyan')
plt.xlabel('Class')
plt.ylabel('F1 Score')
plt.title('F1 Scores by Class')
plt.show()

# Print other metrics
print(f"Accuracy: {accuracy}")
print("Classification Report:\n", classification_rep)

print(f"Accuracy: {accuracy}")
print(f"Confusion Matrix:\n{confusion}")
print(f"F1-scores: {f1_scores}")
print(f"Classification Report:\n{classification_rep}")

plt.figure(figsize=(10, 6))
plt.bar(class_auc_roc.keys(), class_auc_roc.values())
plt.xlabel('Class')
plt.ylabel('AUC-ROC Score')
plt.title('AUC-ROC Scores for Each Class')
plt.show()

"""# Transformer code

"""

class CNN_for_transformer(nn.Module):
  def __init__(self):
    super(CNN_for_transformer,self).__init__()

    self.convolution1 = nn.Sequential(
        nn.Conv1d(in_channels=1,out_channels=16,kernel_size=5,stride=2,padding=3),
        nn.BatchNorm1d(16),
        nn.ReLU(),
        nn.MaxPool1d(kernel_size=3,stride=3)
    )

    self.convolution2 = nn.Sequential(
        nn.Conv1d(in_channels=16,out_channels=32,kernel_size=5,stride=2,padding=2),
        nn.BatchNorm1d(32),
        nn.ReLU(),
        nn.MaxPool1d(kernel_size=3,stride=3)
    )

    self.convolution3 = nn.Sequential(
        nn.Conv1d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=2),
        nn.BatchNorm1d(64),
        nn.ReLU(),
        nn.MaxPool1d(kernel_size=3,stride=3)
    )





  def forward(self,x):

    x = self.convolution1(x)

    x = self.convolution2(x)


    features = self.convolution3(x)

    return features

model = CNN_for_transformer()
x = torch.rand(9,1,16000)
print(model(x).shape)

class Positional_encoding(nn.Module):

    def __init__(self, d_model, seq_len , dropout: float) -> None:
        super(Positional_encoding,self).__init__()
        self.d_model = d_model
        self.seq_len = seq_len
        self.dropout = nn.Dropout(dropout)

        pe = torch.zeros(seq_len, d_model)

        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)

        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))

        pe[:, 0::2] = torch.sin(position * div_term)

        pe[:, 1::2] = torch.cos(position * div_term)

        pe = pe.unsqueeze(0)

        self.register_buffer('pe', pe)


    def forward(self, x):

        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)
        # print("pe",x.shape)

        return self.dropout(x)

class FeedForward_layer(nn.Module):

    def __init__(self, d_model: int, d_ff: int, dropout: float):
        super(FeedForward_layer,self).__init__()
        self.linear_1 = nn.Linear(d_model, d_ff) # w1 and b1
        self.dropout = nn.Dropout(dropout)
        self.linear_2 = nn.Linear(d_ff, d_model) # w2 and b2

    def forward(self, x):

        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))

class Multihead_attention(nn.Module):

    def __init__(self, d_model: int, num_heads: int, dropout: float):
        super(Multihead_attention,self).__init__()
        self.d_model = d_model
        self.num_heads = num_heads # Number of heads
        self.drop_out = dropout
        assert d_model % num_heads == 0, "d_model is not divisible by h"

        self.d_k = d_model // num_heads
        self.query_matrix = nn.Linear(d_model, d_model, bias=False)
        self.key_matrix = nn.Linear(d_model, d_model, bias=False)
        self.value_matrix = nn.Linear(d_model, d_model, bias=False)
        self.Output = nn.Linear(d_model, d_model, bias=False)
        self.dropout = nn.Dropout(dropout)



    def forward(self, q, k, v):
        query = self.query_matrix(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)
        key = self.key_matrix(k) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)
        value = self.value_matrix(v) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)

        query = query.view(query.shape[0], query.shape[1], self.num_heads, self.d_k).transpose(1, 2)
        key = key.view(key.shape[0], key.shape[1], self.num_heads, self.d_k).transpose(1, 2)
        value = value.view(value.shape[0], value.shape[1], self.num_heads, self.d_k).transpose(1, 2)


        d_k = query.shape[-1]
        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)
        attention_scores = attention_scores.softmax(dim=-1)
        if self.drop_out is not None:
            attention_scores = self.dropout(attention_scores)
        x = attention_scores @ value




        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.num_heads * self.d_k)
        # print("Multi_head",x.shape)


        return self.Output(x)

class layer_norm(nn.Module):
    def __init__(self, features, epsilon = 1e-4):
        super(layer_norm,self).__init__()

        self.gamma = nn.Parameter(torch.ones(features))
        self.bias = nn.Parameter(torch.zeros(features))
        self.epsilon = epsilon


    def forward(self,x):
        mean= x.mean(-1,keepdim = True)
        std = x.mean(-1,keepdim = True)

        return self.gamma * (x-mean) / (std + self.epsilon) + self.bias

class ResidualConnection(nn.Module):

        def __init__(self, features: int, dropout: float):
            super(ResidualConnection,self).__init__()
            self.dropout = nn.Dropout(dropout)
            self.norm = layer_norm(features)

        def forward(self, x, sublayer):
            return x + self.dropout(sublayer(self.norm(x)))

class EncoderBlock(nn.Module):

    def __init__(self, features: int, self_attention_block: Multihead_attention, feed_forward_block: FeedForward_layer, dropout: float):
        super().__init__()
        self.self_attention_block = self_attention_block
        self.feed_forward_block = feed_forward_block
        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])

    def forward(self, x):
        # print("encoder_block",x.shape)
        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x))
        x = self.residual_connections[1](x, self.feed_forward_block)
        return x

class Encoder(nn.Module):

    def __init__(self, features: int, layers: nn.ModuleList):
        super().__init__()
        self.layers = layers
        self.norm = layer_norm(features)

    def forward(self, x):
        # print("encoder",x.shape)
        for layer in self.layers:
            x = layer(x)
        return self.norm(x)



class CNNTransformer(nn.Module):
    def __init__(self, transformer_d_model, transformer_nhead, transformer_num_layers, transformer_dim_feedforward, transformer_dropout, num_classes):
        super(CNNTransformer, self).__init__()

        self.cnn_transformer = CNN_for_transformer()
        self.cls_token = nn.Parameter(torch.randn(1, 1, transformer_d_model))
        self.positional_encoding = Positional_encoding(d_model=transformer_d_model, seq_len=1000, dropout=0.1)

        self.transformer_blocks = nn.ModuleList([
            EncoderBlock(features=transformer_d_model,
                         self_attention_block=Multihead_attention(d_model=transformer_d_model,
                                                                   num_heads=transformer_nhead,
                                                                   dropout=transformer_dropout),
                         feed_forward_block=FeedForward_layer(d_model=transformer_d_model,
                                                               d_ff=transformer_dim_feedforward,
                                                               dropout=transformer_dropout),
                         dropout=transformer_dropout)
            for _ in range(transformer_num_layers)
        ])

        self.encoder = Encoder(features=transformer_d_model, layers=self.transformer_blocks)

        self.fc = nn.Linear(transformer_d_model, num_classes)

    def forward(self, x):
        cnn_output = self.cnn_transformer(x)
        # Add CLS token

        cls_token = self.cls_token.repeat(cnn_output.size(0), 1, 1)
        cnn_output = torch.cat([cls_token, cnn_output], dim=1)

        positional_encoding = self.positional_encoding(cnn_output)
        # print("main",positional_encoding.shape)
        transformer_output = positional_encoding
        # print("main",transformer_output.shape)
        transformer_output = self.encoder(transformer_output)

        output = self.fc(transformer_output[:, 0, :])  # Taking  output at the first position (CLS token)

        return output

"""# Audio classification using Transformer : n_heads = 4 (Train - val)"""

torch.cuda.empty_cache()

transformer_d_model = 148 # Dimensionality of the model's output
nhead = 4  # Number of attention heads in the Transformer
transformer_num_layers = 2  # Number of layers in the Transformer
transformer_dim_feedforward = 32  # Dimensionality of the feedforward network in the Transformer
transformer_dropout = 0.1  # Dropout rate for regularization
num_classes = 10  # Number of classes to classify the data

# Training Hyperparameters
batch_size = 16  # Number of samples in each mini-batch
num_epochs = 100  # Number of training epochs

torch.manual_seed(42)

CNN_transformer_4 = CNNTransformer(transformer_d_model, nhead, transformer_num_layers, transformer_dim_feedforward, transformer_dropout, num_classes)

CNN_transformer=CNN_transformer_4.to(device)
x = torch.rand(9,1,16000)
print(CNN_transformer_4(x.to(device)).shape)
CNN_transformer_4

x.shape

find_loss = nn.CrossEntropyLoss()
optimizer = optim.SGD(CNN_transformer_4.parameters(), lr=0.01,momentum=0.9,nesterov=True)

#torch.save(CNN_transformer.state_dict(), "best_model_transformer_3.pt")

wandb.login()



run = wandb.init(project="Deep_learning_assignment2", name="Audio classification using Transformer - n_heads = 4 (Train -val)")

for epoch in range(100):
    CNN_transformer_4.train()
    train_batch_loss_tf = 0.0
    correct_predictions_train_tf = 0.0
    total_samples_train_tf = 0

    for i, (input_data_tf, labels_tf) in enumerate(train_data):
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        optimizer.zero_grad()
        output_tf = CNN_transformer_4(input_data_tf)
        Current_Loss_transformer = find_loss(output_tf, labels_tf)

        train_batch_loss_tf += Current_Loss_transformer.item()
        predictions_tf = torch.max(output_tf.data, 1)[1]
        correct_predictions_train_tf += (predictions_tf==labels_tf).sum().item()
        total_samples_train_tf += labels_tf.size(0)

        Current_Loss_transformer.backward()
        optimizer.step()


        average_loss_train_tf = train_batch_loss_tf / len(train_data)
        accuracy_train_tf = (correct_predictions_train_tf / total_samples_train_tf)*100

        # Validation phase
        CNN_transformer_4.eval()
        val_batch_loss_tf = 0.0
        correct_predictions_val_tf = 0.0
        total_samples_val_tf = 0

        with torch.no_grad():
            for input_data_tf, labels_tf in val_data:
                input_data_tf = input_data_tf.to(device)
                labels_tf = labels_tf.to(device)

                output_tf = CNN_transformer_4(input_data_tf)
                current_loss_val_tf = find_loss(output_tf, labels_tf)

                val_batch_loss_tf += current_loss_val_tf.item()
                predictions_val_tf = torch.max(output_tf.data, 1)[1]
                correct_predictions_val_tf += (predictions_val_tf==labels_tf).sum().item()
                total_samples_val_tf += labels_tf.size(0)

        # Calculate average loss and accuracy for validation
        average_loss_val_tf = val_batch_loss_tf / len(val_data)
        accuracy_val_tf = (correct_predictions_val_tf / total_samples_val_tf)*100


    wandb.log({

            "epoch": epoch + 1,
            "train_loss": average_loss_train_tf,
            "train_accuracy": accuracy_train_tf,
            "val_loss": average_loss_val_tf,
            "val_accuracy": accuracy_val_tf
        })

    if (i + 1) % 15 == 0:

             print("Train epoch {} loss: {} Accuracy_train: {} Accuracy_val: {}".format(epoch + 1, Current_Loss_transformer,accuracy_train_tf,accuracy_val_tf))

run.finish()

"""# Audio classification using Transformer : n_heads = 4 (Train - test)"""

torch.manual_seed(42)

CNN_transformer_test_4 = CNNTransformer(transformer_d_model, nhead, transformer_num_layers, transformer_dim_feedforward, transformer_dropout, num_classes)

CNN_transformer_test_4.to(device)

optimizer = optim.SGD(CNN_transformer_test_4.parameters(), lr=0.0007,momentum=0.9)
find_loss = nn.CrossEntropyLoss()

wandb.login()



run = wandb.init(project="Deep_learning_assignment2", name="Audio classification using Transformer - n_heads = 4 (Train - test)")

for epoch in range(100):
    CNN_transformer_test_4.train()
    train_batch_loss_tf = 0.0
    correct_predictions_train_tf = 0.0
    total_samples_train_tf = 0

    for i, (input_data_tf, labels_tf) in enumerate(train_data):
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        optimizer.zero_grad()
        output_tf = CNN_transformer_test_4(input_data_tf)
        Current_Loss_transformer = find_loss(output_tf, labels_tf)

        train_batch_loss_tf += Current_Loss_transformer.item()
        predictions_tf = torch.max(output_tf.data, 1)[1]
        correct_predictions_train_tf += (predictions_tf==labels_tf).sum().item()
        total_samples_train_tf += labels_tf.size(0)

        Current_Loss_transformer.backward()
        optimizer.step()


        average_loss_train_tf = train_batch_loss_tf / len(train_data)
        accuracy_train_tf = (correct_predictions_train_tf / total_samples_train_tf)*100

        # Validation phase
        CNN_transformer_test_4.eval()
        test_batch_loss_tf = 0.0
        correct_predictions_test_tf = 0.0
        total_samples_test_tf = 0

        with torch.no_grad():
            for input_data_tf, labels_tf in test_data:
                input_data_tf = input_data_tf.to(device)
                labels_tf = labels_tf.to(device)

                output_tf = CNN_transformer_test_4(input_data_tf)
                current_loss_test_tf = find_loss(output_tf, labels_tf)

                test_batch_loss_tf += current_loss_test_tf.item()
                predictions_test_tf = torch.max(output_tf.data, 1)[1]
                correct_predictions_test_tf += (predictions_test_tf==labels_tf).sum().item()
                total_samples_test_tf += labels_tf.size(0)

        # Calculate average loss and accuracy for validation
        average_loss_test_tf = test_batch_loss_tf / len(test_data)
        accuracy_test_tf = (correct_predictions_test_tf / total_samples_test_tf)*100


    wandb.log({

            "epoch": epoch + 1,
            "train_loss": average_loss_train_tf,
            "train_accuracy": accuracy_train_tf,
            "test_loss": average_loss_test_tf,
            "test_accuracy": accuracy_test_tf
        })

    if (i + 1) % 15 == 0:

             print("Train epoch {} loss: {} Accuracy_train: {} Accuracy_test: {}".format(epoch + 1, Current_Loss_transformer,accuracy_train_tf,accuracy_test_tf))

run.finish()

test_predictions_tf_4 = []
test_labels_tf_4 = []

with torch.no_grad():
    for input_data_tf, labels_tf in test_data:
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        output_tf = CNN_transformer_test_4(input_data_tf)
        _, predictions_test_tf = torch.max(output_tf.data, 1)

        test_predictions_tf_4.extend(predictions_test_tf.cpu().numpy())
        test_labels_tf_4.extend(labels_tf.cpu().numpy())


accuracy_test_tf = accuracy_score(test_labels_tf_4, test_predictions_tf_4)*100

accuracy_test_tf

accuracy = accuracy_score(test_labels_tf_4, test_predictions_tf_4)
confusion = confusion_matrix(test_labels_tf_4, test_predictions_tf_4)
f1_scores = f1_score(test_labels_tf_4, test_predictions_tf_4, average=None)
classification_rep = classification_report(test_labels_tf_4, test_predictions_tf_4)

class_auc_roc = {}

with torch.no_grad():
    for class_label in set(test_labels_tf_4):

        binary_test_labels = [1 if label == class_label else 0 for label in test_labels_tf_4]
        binary_test_predictions = [1 if pred == class_label else 0 for pred in test_predictions_tf_4]


        auc_roc_class = roc_auc_score(binary_test_labels, binary_test_predictions)


        class_auc_roc[class_label] = auc_roc_class

print("AUC-ROC scores for each class:", class_auc_roc)

class_labels = sorted(list(set(test_labels_tf_4 + test_predictions_tf_4)))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues_r', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Visualize F1 scores
plt.figure(figsize=(10, 6))
plt.bar(class_labels, f1_scores,color = 'cyan')
plt.xlabel('Class')
plt.ylabel('F1 Score')
plt.title('F1 Scores by Class')
plt.show()

# Print other metrics
print(f"Accuracy: {accuracy}")
print("Classification Report:\n", classification_rep)

print(f"Accuracy: {accuracy}")
print(f"Confusion Matrix:\n{confusion}")
print(f"F1-scores: {f1_scores}")
print(f"Classification Report:\n{classification_rep}")

plt.figure(figsize=(10, 6))
plt.bar(class_auc_roc.keys(), class_auc_roc.values())
plt.xlabel('Class')
plt.ylabel('AUC-ROC Score')
plt.title('AUC-ROC Scores for Each Class')
plt.show()



"""# Audio classification using Transformer : n_heads = 2 (Train - val)"""

torch.cuda.empty_cache()

transformer_d_model = 148 # Dimensionality of the model's output
nhead = 2  # Number of attention heads in the Transformer
transformer_num_layers = 2  # Number of layers in the Transformer
transformer_dim_feedforward = 32  # Dimensionality of the feedforward network in the Transformer
transformer_dropout = 0.1  # Dropout rate for regularization
num_classes = 10  # Number of classes to classify the data

torch.manual_seed(42)

CNN_transformer_2 = CNNTransformer(transformer_d_model, nhead, transformer_num_layers, transformer_dim_feedforward, transformer_dropout, num_classes)

CNN_transformer_2.to(device)

CNN_transformer_2

find_loss = nn.CrossEntropyLoss()
optimizer = optim.SGD(CNN_transformer_2.parameters(), lr=0.007,momentum=0.9)

wandb.login()



run = wandb.init(project="Deep_learning_assignment2", name="Audio classification using Transformer - n_heads = 2 (Train -val)")

for epoch in range(100):
    CNN_transformer_2.train()
    train_batch_loss_tf = 0.0
    correct_predictions_train_tf = 0.0
    total_samples_train_tf = 0

    for i, (input_data_tf, labels_tf) in enumerate(train_data):
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        optimizer.zero_grad()
        output_tf = CNN_transformer_2(input_data_tf)
        Current_Loss_transformer = find_loss(output_tf, labels_tf)

        train_batch_loss_tf += Current_Loss_transformer.item()
        predictions_tf = torch.max(output_tf.data, 1)[1]
        correct_predictions_train_tf += (predictions_tf==labels_tf).sum().item()
        total_samples_train_tf += labels_tf.size(0)

        Current_Loss_transformer.backward()
        optimizer.step()

        # Calculate average loss and accuracy for training
        average_loss_train_tf = train_batch_loss_tf / len(train_data)
        accuracy_train_tf = (correct_predictions_train_tf / total_samples_train_tf)*100

        # Validation phase
        CNN_transformer_2.eval()
        val_batch_loss_tf = 0.0
        correct_predictions_val_tf = 0.0
        total_samples_val_tf = 0

        with torch.no_grad():
            for input_data_tf, labels_tf in val_data:
                input_data_tf = input_data_tf.to(device)
                labels_tf = labels_tf.to(device)

                output_tf = CNN_transformer_2(input_data_tf)
                current_loss_val_tf = find_loss(output_tf, labels_tf)

                val_batch_loss_tf += current_loss_val_tf.item()
                predictions_val_tf = torch.max(output_tf.data, 1)[1]
                correct_predictions_val_tf += (predictions_val_tf==labels_tf).sum().item()
                total_samples_val_tf += labels_tf.size(0)

        # Calculate average loss and accuracy for validation
        average_loss_val_tf = val_batch_loss_tf / len(val_data)
        accuracy_val_tf = (correct_predictions_val_tf / total_samples_val_tf)*100


    wandb.log({

            "epoch": epoch + 1,
            "train_loss": average_loss_train_tf,
            "train_accuracy": accuracy_train_tf,
            "val_loss": average_loss_val_tf,
            "val_accuracy": accuracy_val_tf
        })

    if (i + 1) % 15 == 0:

             print("Train epoch {} loss: {} Accuracy_train: {} Accuracy_val: {}".format(epoch + 1, Current_Loss_transformer,accuracy_train_tf,accuracy_val_tf))

run.finish()

"""#  Audio classification using Transformer : n_heads = 2 (Train - test)"""

torch.manual_seed(42)

CNN_transformer_test_2 = CNNTransformer(transformer_d_model, nhead, transformer_num_layers, transformer_dim_feedforward, transformer_dropout, num_classes)

CNN_transformer_test_2.to(device)

optimizer = optim.SGD(CNN_transformer_test_2.parameters(), lr=0.0007,momentum=0.9)
find_loss = nn.CrossEntropyLoss()

wandb.login()



run = wandb.init(project="Deep_learning_assignment2", name="Audio classification using Transformer - n_heads = 2 (Train - test)")

for epoch in range(100):
    CNN_transformer_test_2.train()
    train_batch_loss_tf = 0.0
    correct_predictions_train_tf = 0.0
    total_samples_train_tf = 0

    for i, (input_data_tf, labels_tf) in enumerate(train_data):
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        optimizer.zero_grad()
        output_tf = CNN_transformer_test_2(input_data_tf)
        Current_Loss_transformer = find_loss(output_tf, labels_tf)

        train_batch_loss_tf += Current_Loss_transformer.item()
        predictions_tf = torch.max(output_tf.data, 1)[1]
        correct_predictions_train_tf += (predictions_tf==labels_tf).sum().item()
        total_samples_train_tf += labels_tf.size(0)

        Current_Loss_transformer.backward()
        optimizer.step()


        average_loss_train_tf = train_batch_loss_tf / len(train_data)
        accuracy_train_tf = (correct_predictions_train_tf / total_samples_train_tf)*100

        # Validation phase
        CNN_transformer_test_2.eval()
        test_batch_loss_tf = 0.0
        correct_predictions_test_tf = 0.0
        total_samples_test_tf = 0

        with torch.no_grad():
            for input_data_tf, labels_tf in test_data:
                input_data_tf = input_data_tf.to(device)
                labels_tf = labels_tf.to(device)

                output_tf = CNN_transformer_test_2(input_data_tf)
                current_loss_test_tf = find_loss(output_tf, labels_tf)

                test_batch_loss_tf += current_loss_test_tf.item()
                predictions_test_tf = torch.max(output_tf.data, 1)[1]
                correct_predictions_test_tf += (predictions_test_tf==labels_tf).sum().item()
                total_samples_test_tf += labels_tf.size(0)

        # Calculate average loss and accuracy for validation
        average_loss_test_tf = test_batch_loss_tf / len(test_data)
        accuracy_test_tf = (correct_predictions_test_tf / total_samples_test_tf)*100


    wandb.log({

            "epoch": epoch + 1,
            "train_loss": average_loss_train_tf,
            "train_accuracy": accuracy_train_tf,
            "test_loss": average_loss_test_tf,
            "test_accuracy": accuracy_test_tf
        })

    if (i + 1) % 15 == 0:

             print("Train epoch {} loss: {} Accuracy_train: {} Accuracy_test: {}".format(epoch + 1, Current_Loss_transformer,accuracy_train_tf,accuracy_test_tf))

run.finish()

test_predictions_tf_2 = []
test_labels_tf_2 = []

with torch.no_grad():
    for input_data_tf, labels_tf in test_data:
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        output_tf = CNN_transformer_test_2(input_data_tf)
        _, predictions_test_tf = torch.max(output_tf.data, 1)

        test_predictions_tf_2.extend(predictions_test_tf.cpu().numpy())
        test_labels_tf_2.extend(labels_tf.cpu().numpy())


accuracy_test_tf = accuracy_score(test_labels_tf_2, test_predictions_tf_2)*100

accuracy_test_tf

accuracy = accuracy_score(test_labels_tf_2, test_predictions_tf_2)
confusion = confusion_matrix(test_labels_tf_2, test_predictions_tf_2)
f1_scores = f1_score(test_labels_tf_2, test_predictions_tf_2, average=None)
classification_rep = classification_report(test_labels_tf_2, test_predictions_tf_2)

class_auc_roc = {}

with torch.no_grad():
    for class_label in set(test_labels_tf_2):

        binary_test_labels = [1 if label == class_label else 0 for label in test_labels_tf_2]
        binary_test_predictions = [1 if pred == class_label else 0 for pred in test_predictions_tf_2]


        auc_roc_class = roc_auc_score(binary_test_labels, binary_test_predictions)


        class_auc_roc[class_label] = auc_roc_class

print("AUC-ROC scores for each class:", class_auc_roc)

class_labels = sorted(list(set(test_labels_tf_2 + test_predictions_tf_2)))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues_r', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Visualize F1 scores
plt.figure(figsize=(10, 6))
plt.bar(class_labels, f1_scores,color = 'cyan')
plt.xlabel('Class')
plt.ylabel('F1 Score')
plt.title('F1 Scores by Class')
plt.show()

# Print other metrics
print(f"Accuracy: {accuracy}")
print("Classification Report:\n", classification_rep)

print(f"Accuracy: {accuracy}")
print(f"Confusion Matrix:\n{confusion}")
print(f"F1-scores: {f1_scores}")
print(f"Classification Report:\n{classification_rep}")

plt.figure(figsize=(10, 6))
plt.bar(class_auc_roc.keys(), class_auc_roc.values())
plt.xlabel('Class')
plt.ylabel('AUC-ROC Score')
plt.title('AUC-ROC Scores for Each Class')
plt.show()

"""# Audio classification using Transformer : n_heads = 1 (Train - val)"""

torch.cuda.empty_cache()

transformer_d_model = 148 # Dimensionality of the model's output
nhead = 1  # Number of attention heads in the Transformer
transformer_num_layers = 2  # Number of layers in the Transformer
transformer_dim_feedforward = 32  # Dimensionality of the feedforward network in the Transformer
transformer_dropout = 0.1  # Dropout rate for regularization
num_classes = 10  # Number of classes to classify the data

torch.manual_seed(42)

CNN_transformer_1 = CNNTransformer(transformer_d_model, nhead, transformer_num_layers, transformer_dim_feedforward, transformer_dropout, num_classes)

CNN_transformer_1.to(device)

CNN_transformer_1

find_loss = nn.CrossEntropyLoss()
optimizer = optim.SGD(CNN_transformer_1.parameters(), lr=0.007,momentum=0.9)

wandb.login()



run = wandb.init(project="Deep_learning_assignment2", name="Audio classification using Transformer - n_heads = 1 (Train -val)")

for epoch in range(100):
    CNN_transformer_1.train()
    train_batch_loss_tf = 0.0
    correct_predictions_train_tf = 0.0
    total_samples_train_tf = 0

    for i, (input_data_tf, labels_tf) in enumerate(train_data):
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        optimizer.zero_grad()
        output_tf = CNN_transformer_1(input_data_tf)
        Current_Loss_transformer = find_loss(output_tf, labels_tf)

        train_batch_loss_tf += Current_Loss_transformer.item()
        predictions_tf = torch.max(output_tf.data, 1)[1]
        correct_predictions_train_tf += (predictions_tf==labels_tf).sum().item()
        total_samples_train_tf += labels_tf.size(0)

        Current_Loss_transformer.backward()
        optimizer.step()


        average_loss_train_tf = train_batch_loss_tf / len(train_data)
        accuracy_train_tf = (correct_predictions_train_tf / total_samples_train_tf)*100

        # Validation phase
        CNN_transformer_1.eval()
        val_batch_loss_tf = 0.0
        correct_predictions_val_tf = 0.0
        total_samples_val_tf = 0

        with torch.no_grad():
            for input_data_tf, labels_tf in val_data:
                input_data_tf = input_data_tf.to(device)
                labels_tf = labels_tf.to(device)

                output_tf = CNN_transformer_1(input_data_tf)
                current_loss_val_tf = find_loss(output_tf, labels_tf)

                val_batch_loss_tf += current_loss_val_tf.item()
                predictions_val_tf = torch.max(output_tf.data, 1)[1]
                correct_predictions_val_tf += (predictions_val_tf==labels_tf).sum().item()
                total_samples_val_tf += labels_tf.size(0)

        # Calculate average loss and accuracy for validation
        average_loss_val_tf = val_batch_loss_tf / len(val_data)
        accuracy_val_tf = (correct_predictions_val_tf / total_samples_val_tf)*100


    wandb.log({

            "epoch": epoch + 1,
            "train_loss": average_loss_train_tf,
            "train_accuracy": accuracy_train_tf,
            "val_loss": average_loss_val_tf,
            "val_accuracy": accuracy_val_tf
        })

    if (i + 1) % 15 == 0:

             print("Train epoch {} loss: {} Accuracy_train: {} Accuracy_val: {}".format(epoch + 1, Current_Loss_transformer,accuracy_train_tf,accuracy_val_tf))

run.finish()

"""#  Audio classification using Transformer : n_heads = 1 (Train - test)"""

torch.cuda.empty_cache()

torch.manual_seed(42)

CNN_transformer_test_1 = CNNTransformer(transformer_d_model, nhead, transformer_num_layers, transformer_dim_feedforward, transformer_dropout, num_classes)

CNN_transformer_test_1.to(device)

optimizer = optim.SGD(CNN_transformer_test_1.parameters(), lr=0.0007,momentum=0.9)
find_loss = nn.CrossEntropyLoss()

wandb.login()



run = wandb.init(project="Deep_learning_assignment2", name="Audio classification using Transformer - n_heads = 1 (Train - test)")

for epoch in range(100):
    CNN_transformer_test_1.train()
    train_batch_loss_tf = 0.0
    correct_predictions_train_tf = 0.0
    total_samples_train_tf = 0

    for i, (input_data_tf, labels_tf) in enumerate(train_data):
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        optimizer.zero_grad()
        output_tf = CNN_transformer_test_1(input_data_tf)
        Current_Loss_transformer = find_loss(output_tf, labels_tf)

        train_batch_loss_tf += Current_Loss_transformer.item()
        predictions_tf = torch.max(output_tf.data, 1)[1]
        correct_predictions_train_tf += (predictions_tf==labels_tf).sum().item()
        total_samples_train_tf += labels_tf.size(0)

        Current_Loss_transformer.backward()
        optimizer.step()


        average_loss_train_tf = train_batch_loss_tf / len(train_data)
        accuracy_train_tf = (correct_predictions_train_tf / total_samples_train_tf)*100

        # Validation phase
        CNN_transformer_test_1.eval()
        test_batch_loss_tf = 0.0
        correct_predictions_test_tf = 0.0
        total_samples_test_tf = 0

        with torch.no_grad():
            for input_data_tf, labels_tf in test_data:
                input_data_tf = input_data_tf.to(device)
                labels_tf = labels_tf.to(device)

                output_tf = CNN_transformer_test_1(input_data_tf)
                current_loss_test_tf = find_loss(output_tf, labels_tf)

                test_batch_loss_tf += current_loss_test_tf.item()
                predictions_test_tf = torch.max(output_tf.data, 1)[1]
                correct_predictions_test_tf += (predictions_test_tf==labels_tf).sum().item()
                total_samples_test_tf += labels_tf.size(0)

        # Calculate average loss and accuracy for validation
        average_loss_test_tf = test_batch_loss_tf / len(test_data)
        accuracy_test_tf = (correct_predictions_test_tf / total_samples_test_tf)*100


    wandb.log({

            "epoch": epoch + 1,
            "train_loss": average_loss_train_tf,
            "train_accuracy": accuracy_train_tf,
            "test_loss": average_loss_test_tf,
            "test_accuracy": accuracy_test_tf
        })

    if (i + 1) % 15 == 0:

             print("Train epoch {} loss: {} Accuracy_train: {} Accuracy_test: {}".format(epoch + 1, Current_Loss_transformer,accuracy_train_tf,accuracy_test_tf))

run.finish()

test_predictions_tf = []
test_labels_tf = []

with torch.no_grad():
    for input_data_tf, labels_tf in test_data:
        input_data_tf = input_data_tf.to(device)
        labels_tf = labels_tf.to(device)

        output_tf = CNN_transformer_test_1(input_data_tf)
        _, predictions_test_tf = torch.max(output_tf.data, 1)

        test_predictions_tf.extend(predictions_test_tf.cpu().numpy())
        test_labels_tf.extend(labels_tf.cpu().numpy())


accuracy_test_tf = accuracy_score(test_labels_tf, test_predictions_tf)*100

accuracy_test_tf

test_labels_one_hot_tf_1 = label_binarize(test_labels_tf, classes=[0, 1, 2,3,4,5,6,7,8, 9])

accuracy = accuracy_score(test_labels_tf, test_predictions_tf)
confusion = confusion_matrix(test_labels_tf, test_predictions_tf)
f1_scores = f1_score(test_labels_tf, test_predictions_tf, average=None)
classification_rep = classification_report(test_labels_tf, test_predictions_tf)

class_auc_roc = {}

with torch.no_grad():
    for class_label in set(test_labels_tf):

        binary_test_labels = [1 if label == class_label else 0 for label in test_labels_tf]
        binary_test_predictions = [1 if pred == class_label else 0 for pred in test_predictions_tf]


        auc_roc_class = roc_auc_score(binary_test_labels, binary_test_predictions)


        class_auc_roc[class_label] = auc_roc_class

print("AUC-ROC scores for each class:", class_auc_roc)

class_labels = sorted(list(set(test_labels_tf + test_predictions_tf)))

plt.figure(figsize=(8, 6))
sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues_r', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Visualize F1 scores
plt.figure(figsize=(10, 6))
plt.bar(class_labels, f1_scores,color = 'cyan')
plt.xlabel('Class')
plt.ylabel('F1 Score')
plt.title('F1 Scores by Class')
plt.show()

# Print other metrics
print(f"Accuracy: {accuracy}")
print("Classification Report:\n", classification_rep)

print(f"Accuracy: {accuracy}")
print(f"Confusion Matrix:\n{confusion}")
print(f"F1-scores: {f1_scores}")
print(f"Classification Report:\n{classification_rep}")
# print(f"AUC-ROC: {auc_roc}")

plt.figure(figsize=(10, 6))
plt.bar(class_auc_roc.keys(), class_auc_roc.values())
plt.xlabel('Class')
plt.ylabel('AUC-ROC Score')
plt.title('AUC-ROC Scores for Each Class')
plt.show()



